Django + Celery
---
**Celery** - нужен для запуска задач в отдельном рабочем
процессе (worker), что позволяет немедленно отправить HTTP-ответ
пользователю в веб-процессе (даже если задача в рабочем процессе
все еще выполняется). Цикл обработки запроса не будет заблокирован,
что повысит качество взаимодействия с пользователем.

**worker** - отдельный рабочий процесс, который берется за 
выполнение некой задачи в фоновом режиме. 

Варианты использования:

- Обработка отправки 10 электронных писем, В данном случае Celery
может организовать отправку писем в фоновом режиме, что в свою
очередь позволит вернуть HTTP-ответ пользователю без ожидания.

- Необходимо делать что-то периодически, например, генерировать
ежедневный отчет, очищать данные истекшей сессии.

Сельдерей требует решения для отправки и получения сообщений,
обычно это осуществляется в виде отдельной службы, называемой
брокером сообщений.

Существует 2 брокера сообщений для работы с Celery:

1. Celery 
2. RQ (Redis Queue)

Celery я работы использует свои таблицы в Бд, так что надо выполнить
миграции перед его использованием.

---
Брокеры сообщений.
---

Брокер сообщений — это хранилище, которое играет роль транспорта
между производителем и потребителем. Из документации Celery
рекомендуемым брокером является RabbitMQ, потому что он поддерживает
AMQP (расширенный протокол очереди сообщений).

Так как во многих случаях нам не нужно использовать AMQP, другой 
диспетчер очереди, такой как Redis, также подойдет. 

Бэкенд результатов — это хранилище, которое содержит информацию
о результатах выполнения Celery-задач и о возникших ошибках.

Брокеры сообщений используемые Celery:

1. Redis
2. RabbitMQ

---

По сути Брокер это БД в оперативной памяти, что позволяет хранить
сообщения между приложениями, используется не обычная Бд типа 
PostgreSQL, а БД в оперативной памяти, такие как Redis, RabbitMQ.

Чтобы удобно следить за выполнением задач, какие задачи запущены 
или сломаны, можно использовать как терминал, так и специальное
приложение `flower`

Таски - это к примеру функции которые выполняют некоторые задачи,
у тасков можно настраивать приоритеты, какие выполнять раньше 
других, таски можно запускать как в ручную, так и в определенный
интервал времени.

Работая с тасками, нельзя использовать ORM самого джанго внутри
тасков.

`Flower` - можно запускать и в браузере, с красивым отображением
всех воркеров, и всех работающих тасков.



---

Redis
---

Стандартно Redis запускается на `127.0.0.1:6379` 

Можно использовать как Redis в основной системе, так и в контейнере
Docker следующим образом

    docker run -d -p 6379:6379 redis

Установка Redis 

    sudo apt install redis-server

Запуск Redis и добавление в автозагрузку

    sudo systemctl start redis-server
    sudo systemctl enable redis-server

Узнать версию 

    redis-server --version

Проверить, состояние сервера

    service redis status

Остановка сервера

    service redis stop

Запуск сервера

    service redis start

---

flower
---

Flower – это легкий веб-инструмент для мониторинга Celery в 
режиме реального времени. Вы можете отслеживать запущенные
задания, увеличивать или уменьшать пул воркеров, отображать
графики и статистику.

---

Установка Celery 
---

Установка пакетов для работы Celery

    pip3 install celery==5.0.5 redis==3.5.3 flower==0.9.7

Или установка Celery совместно с другими пакетами для работы.

Для использования Redis в качестве транспорта сообщений 
или в качестве бэкэнда:

    pip3 install "celery[redis]"

Или в место Redis используем RabbitMQ 

    pip3 install "celery[librabbitmq]"

---
Настройка Celery
---

У Celery есть ряд параметров которые управляют его поведением, если 
мы создаем Django приложение через `Cookiecutter` то он может сам
дополнить приложение дефолтными настройками, которые могут нас не 
удовлетворять, рассмотрим настройки для `Celery`: 

---
Отключает отображение задач Celery, задачи выполняются, но мы этого
не видим, в сервисе `Flower` таски тоже не будут отображаться 

    CELERY_TASK_ALWAYS_EAGER = True
---

Если внутри таска появляется исключение, то оно будет выбрасываться
в основной поток программы

    CELERY_TASK_EAGER_PROPAGATES = True
---

Установка временной зоны

    CELERY_TIMEZONE = TIME_ZONE
---
Указываем что использовать как брокер сообщений, что как бэкенд 
результатов, в данном случае используем только `Redis` как то и 
другое

    CELERY_BROKER_URL = 'redis://127.0.0.1:6379/0'
    CELERY_RESULT_BACKEND = CELERY_BROKER_URL

---
Сериализация данных, приходящих в таск и отдаваемых обратно

    CELERY_ACCEPT_CONTENT = ["json"]
    CELERY_TASK_SERIALIZER = "json"
    CELERY_RESULT_SERIALIZER = "json"

---    
**Жесткое ограничение по времени**

Максимальное время на выполнение таска, по дефолту безграничное, если
таск не выполняется за это время, тоон будет убит и заменен на новый,
время указывается в секундах

    # 10 минут
    CELERY_TASK_TIME_LIMIT = 10 * 60

---
**Мягкое ограничение по времени**

[Почитать тут](http://docs.celeryproject.org/en/latest/userguide/configuration.html#task-soft-time-limit)

Если задача предусматривает быстрое выполнение, то мы можем установить
мягкое ограничение по времени в секундах, если таск превышает это время 
выполнения, то генерируется специальное иcключение, оно ни на что не 
влияет и служит в качестве оповещения, мы можем его перехватить и
решить остановить таск досрочно или нет.

    CELERY_TASK_SOFT_TIME_LIMIT = 60

---
Используя Celery в качестве `crone` для периодического выполнения 
задач, тут указывается класс который будет отвечать за планирование
задач

    CELERY_BEAT_SCHEDULER = "django_celery_beat.schedulers:DatabaseScheduler"
